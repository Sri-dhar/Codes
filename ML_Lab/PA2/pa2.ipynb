{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Create a dataset of size 30x2, where the first column represents the number of hours\n",
    "of sunshine and the second column represents the number of ice creams sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Hours of Sunshine\": [5, 8, 3, 6, 7, 4, 9, 2, 10, 5, 8, 3, 7, 6, 4, 9, 2, 10, 5, 8, 3, 6, 7, 4, 9, 2, 10, 5, 8, 3, 6],\n",
    "    \"Ice Creams Sold\": [150, 200, 100, 180, 210, 130, 220, 90, 250, 160, 190, 110, 230, 170, 120, 240, 80, 260, 140, 210, 95, 175, 220, 125, 230, 85, 255, 155, 205, 105, 140]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('sunshine_ice_cream_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Hours of Sunshine  Ice Creams Sold\n",
      "0                   5              150\n",
      "1                   8              200\n",
      "2                   3              100\n",
      "3                   6              180\n",
      "4                   7              210\n",
      "5                   4              130\n",
      "6                   9              220\n",
      "7                   2               90\n",
      "8                  10              250\n",
      "9                   5              160\n",
      "10                  8              190\n",
      "11                  3              110\n",
      "12                  7              230\n",
      "13                  6              170\n",
      "14                  4              120\n",
      "15                  9              240\n",
      "16                  2               80\n",
      "17                 10              260\n",
      "18                  5              140\n",
      "19                  8              210\n",
      "20                  3               95\n",
      "21                  6              175\n",
      "22                  7              220\n",
      "23                  4              125\n",
      "24                  9              230\n",
      "25                  2               85\n",
      "26                 10              255\n",
      "27                  5              155\n",
      "28                  8              205\n",
      "29                  3              105\n",
      "30                  6              140\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"sunshine_ice_cream_data.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hours of Sunshine  Ice Creams Sold\n",
      "0                  5              150\n",
      "1                  8              200\n",
      "2                  3              100\n",
      "3                  6              180\n",
      "4                  7              210\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the total number of\n",
    "rows and columns in the dataset, and the range of each featureâ€™s values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 30\n",
      "columns: 2\n",
      "Range of Output : (np.int64(80), np.int64(260))\n"
     ]
    }
   ],
   "source": [
    "np_data = np.array(data)\n",
    "\n",
    "print(f\"rows: {data.shape[0]-1}\")\n",
    "print(f\"columns: {data.shape[1]}\")\n",
    "\n",
    "output_column = np_data[:, -1]\n",
    "output_range = (np.min(output_column), np.max(output_column))\n",
    "print(f\"Range of Output : {output_range}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.ii\n",
    "Write a Python program to randomly split the dataset into training and testing\n",
    "sets using the following ratios: 70-30,80-20,90-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 21\n",
      "Test data size: 9\n",
      "\n",
      "Train data size: 24\n",
      "Test data size: 6\n",
      "\n",
      "Train data size: 27\n",
      "Test data size: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_splits = [.7, .8, .9]\n",
    "x_splits = np.array(x_splits)\n",
    "\n",
    "def splitter(data, x): \n",
    "    y = 1-x                  \n",
    "    size = data.shape[0]\n",
    "    train_size = int(size * x)\n",
    "    test_size = int(size * y)\n",
    "    train_data = data[:train_size, :]\n",
    "    test_data = data[train_size:train_size+test_size, :]\n",
    "    return train_data, test_data\n",
    "\n",
    "for x in x_splits:\n",
    "    train_data, test_data = splitter(np_data, x)\n",
    "    print(f\"Train data size: {train_data.shape[0]}\")\n",
    "    print(f\"Test data size: {test_data.shape[0]}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.iii \n",
    "Apply Simple Linear Regression to predict the number of ice creams sold based\n",
    "on the number of hours of sunshine. Report which training and testing split\n",
    "yields the best results.Validate your model using the Mean Squared Error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "X = np.array([5, 8, 3, 6, 7, 4, 9, 2, 10, 5, 8, 3, 7, 6, 4, 9, 2, 10, 5, 8, 3, 6, 7, 4, 9, 2, 10, 5, 8, 3, 6])\n",
    "Y = np.array([150, 200, 100, 180, 210, 130, 220, 90, 250, 160, 190, 110, 230, 170, 120, 240, 80, 260, 140, 210, 95, 175, 220, 125, 230, 85, 255, 155, 205, 105, 140])\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "\n",
    "# Split into training and testing sets\n",
    "split_index = int(0.7 * len(X))\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = Y[:split_index], Y[split_index:]\n",
    "\n",
    "mean_X_train = np.mean(X_train)\n",
    "std_X_train = np.std(X_train)\n",
    "mean_Y_train = np.mean(Y_train)\n",
    "std_Y_train = np.std(Y_train)\n",
    "\n",
    "X_train_scaled = (X_train - mean_X_train) / std_X_train\n",
    "Y_train_scaled = (Y_train - mean_Y_train) / std_Y_train\n",
    "X_test_scaled = (X_test - mean_X_train) / std_X_train\n",
    "Y_test_scaled = (Y_test - mean_Y_train) / std_Y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_regression(X, Y):\n",
    "    n = len(X)\n",
    "    X_mean = np.mean(X)\n",
    "    Y_mean = np.mean(Y)\n",
    "    \n",
    "    numerator = np.sum((X - X_mean) * (Y - Y_mean))\n",
    "    denominator = np.sum((X - X_mean) ** 2)\n",
    "    \n",
    "    w_1 = numerator / denominator\n",
    "    w_0 = Y_mean - w_1 * X_mean\n",
    "    \n",
    "    return w_0, w_1\n",
    "\n",
    "w_0, w_1 = simple_linear_regression(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w_0, w_1):\n",
    "    return w_0 + w_1 * X\n",
    "\n",
    "Y_pred_train = predict(X_train, w_0, w_1)\n",
    "Y_pred_test = predict(X_test, w_0, w_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Training Data: 226.31948595337713\n",
      "MSE for Testing Data: 54.82253418182451\n"
     ]
    }
   ],
   "source": [
    "def mean_squared_error(Y, Y_pred):\n",
    "    return np.mean((Y - Y_pred) ** 2)\n",
    "\n",
    "mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "\n",
    "print(f'MSE for Training Data: {mse_train}')\n",
    "print(f'MSE for Testing Data: {mse_test}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without using np.polyfit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Ratio: 0.7\n",
      "  Training MSE: 183.3346619897959\n",
      "  Testing MSE: 143.3770689672353\n",
      "---\n",
      "Split Ratio: 0.8\n",
      "  Training MSE: 161.74611773203324\n",
      "  Testing MSE: 200.82026348439823\n",
      "---\n",
      "Split Ratio: 0.9\n",
      "  Training MSE: 161.5390011223344\n",
      "  Testing MSE: 231.4842115919291\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([5, 8, 3, 6, 7, 4, 9, 2, 10, 5, 8, 3, 7, 6, 4, 9, 2, 10, 5, 8, 3, 6, 7, 4, 9, 2, 10, 5, 8, 3, 6])\n",
    "Y = np.array([150, 200, 100, 180, 210, 130, 220, 90, 250, 160, 190, 110, 230, 170, 120, 240, 80, 260, 140, 210, 95, 175, 220, 125, 230, 85, 255, 155, 205, 105, 140])\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "\n",
    "def simple_linear_regression(X, Y, standardized=False):\n",
    "    if not standardized:\n",
    "        X_mean = np.mean(X)\n",
    "        X_std = np.std(X, ddof=1)  \n",
    "        Y_mean = np.mean(Y)\n",
    "        Y_std = np.std(Y, ddof=1)\n",
    "        \n",
    "        X = (X - X_mean) / X_std\n",
    "        Y = (Y - Y_mean) / Y_std\n",
    "\n",
    "    XY_sum = np.sum(X * Y)\n",
    "    X2_sum = np.sum(X ** 2)\n",
    "    w_1 = XY_sum / X2_sum\n",
    "    w_0 = 0  \n",
    "\n",
    "    return w_0, w_1\n",
    "\n",
    "def predict(X, w_0, w_1):\n",
    "    return w_0 + w_1 * X\n",
    "\n",
    "def mean_squared_error(Y, Y_pred):\n",
    "    return np.mean((Y - Y_pred) ** 2)\n",
    "\n",
    "def evaluate_split(split_ratio):\n",
    "    split_index = int(split_ratio * len(X))\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    Y_train, Y_test = Y[:split_index], Y[split_index:]\n",
    "\n",
    "    mean_X_train = np.mean(X_train)\n",
    "    std_X_train = np.std(X_train, ddof=1)\n",
    "    mean_Y_train = np.mean(Y_train)\n",
    "    std_Y_train = np.std(Y_train, ddof=1)\n",
    "\n",
    "    X_train_scaled = (X_train - mean_X_train) / std_X_train\n",
    "    Y_train_scaled = (Y_train - mean_Y_train) / std_Y_train\n",
    "    X_test_scaled = (X_test - mean_X_train) / std_X_train\n",
    "    Y_test_scaled = (Y_test - mean_Y_train) / std_Y_train\n",
    "\n",
    "    w_0, w_1 = simple_linear_regression(X_train_scaled, Y_train_scaled, standardized=True)\n",
    "\n",
    "    Y_pred_train_scaled = predict(X_train_scaled, w_0, w_1)\n",
    "    Y_pred_test_scaled = predict(X_test_scaled, w_0, w_1)\n",
    "\n",
    "    Y_pred_train = Y_pred_train_scaled * std_Y_train + mean_Y_train\n",
    "    Y_pred_test = Y_pred_test_scaled * std_Y_train + mean_Y_train\n",
    "\n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "\n",
    "    print(f'Split Ratio: {split_ratio}')\n",
    "    print(f'  Training MSE: {mse_train}')\n",
    "    print(f'  Testing MSE: {mse_test}')\n",
    "\n",
    "for ratio in [0.7, 0.8, 0.9]:\n",
    "    evaluate_split(ratio)\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using np.polyfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Ratio: 0.7\n",
      "  Training MSE: 148.6667818475006\n",
      "  Testing MSE: 215.00731919673672\n",
      "---\n",
      "Split Ratio: 0.8\n",
      "  Training MSE: 131.8702493808182\n",
      "  Testing MSE: 300.4621207899034\n",
      "---\n",
      "Split Ratio: 0.9\n",
      "  Training MSE: 194.4584490233329\n",
      "  Testing MSE: 3.5779214830747508\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def standardize_data(X, Y):\n",
    "    X_mean = np.mean(X)\n",
    "    X_std = np.std(X, ddof=1)\n",
    "    Y_mean = np.mean(Y)\n",
    "    Y_std = np.std(Y, ddof=1)\n",
    "    \n",
    "    X_scaled = (X - X_mean) / X_std\n",
    "    Y_scaled = (Y - Y_mean) / Y_std\n",
    "    \n",
    "    return X_scaled, Y_scaled, X_mean, X_std, Y_mean, Y_std\n",
    "\n",
    "def fit_linear_regression(X, Y, degree=1):\n",
    "    coefficients = np.polyfit(X, Y, degree)\n",
    "    return coefficients\n",
    "\n",
    "def predict(X, coefficients):\n",
    "    return np.polyval(coefficients, X)\n",
    "\n",
    "def mean_squared_error(Y, Y_pred):\n",
    "    return np.mean((Y - Y_pred) ** 2)\n",
    "\n",
    "def evaluate_split(split_ratio):\n",
    "    split_index = int(split_ratio * len(X))\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    Y_train, Y_test = Y[:split_index], Y[split_index:]\n",
    "\n",
    "    X_train_scaled, Y_train_scaled, X_mean, X_std, Y_mean, Y_std = standardize_data(X_train, Y_train)\n",
    "    X_test_scaled = (X_test - X_mean) / X_std\n",
    "    \n",
    "    coefficients = fit_linear_regression(X_train_scaled, Y_train_scaled)\n",
    "\n",
    "    Y_pred_train_scaled = predict(X_train_scaled, coefficients)\n",
    "    Y_pred_test_scaled = predict(X_test_scaled, coefficients)\n",
    "    \n",
    "    Y_pred_train = Y_pred_train_scaled * Y_std + Y_mean\n",
    "    Y_pred_test = Y_pred_test_scaled * Y_std + Y_mean\n",
    "    \n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "\n",
    "    print(f'Split Ratio: {split_ratio}')\n",
    "    print(f'  Training MSE: {mse_train}')\n",
    "    print(f'  Testing MSE: {mse_test}')\n",
    "\n",
    "X = np.array([5, 8, 3, 6, 7, 4, 9, 2, 10, 5, 8, 3, 7, 6, 4, 9, 2, 10, 5, 8, 3, 6, 7, 4, 9, 2, 10, 5, 8, 3, 6])\n",
    "Y = np.array([150, 200, 100, 180, 210, 130, 220, 90, 250, 160, 190, 110, 230, 170, 120, 240, 80, 260, 140, 210, 95, 175, 220, 125, 230, 85, 255, 155, 205, 105, 140])\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "\n",
    "for ratio in [0.7, 0.8, 0.9]:\n",
    "    evaluate_split(ratio)\n",
    "    print('---')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
