{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  MonthlyCharges  ContractType  Tenure  Churn\n",
      "0     56          183.36             0      27      1\n",
      "1     69           64.87             1      66      0\n",
      "2     46           93.87             1       5      0\n",
      "3     32          156.00             1      29      1\n",
      "4     60           61.18             2      37      0\n",
      "..   ...             ...           ...     ...    ...\n",
      "195   66           35.36             1      56      0\n",
      "196   69           29.30             0      63      0\n",
      "197   78          115.64             1      48      0\n",
      "198   49          117.31             0      61      0\n",
      "199   21          134.74             1      26      1\n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"customer_churn_dataset.csv\")\n",
    "df['ContractType'] = df['ContractType'].map({'Monthly': 0, 'One year': 1, 'Two year': 2})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data x :  (120, 4)\n",
      "     Age  MonthlyCharges  ContractType  Tenure\n",
      "0     56          183.36             0      27\n",
      "1     69           64.87             1      66\n",
      "2     46           93.87             1       5\n",
      "3     32          156.00             1      29\n",
      "4     60           61.18             2      37\n",
      "..   ...             ...           ...     ...\n",
      "115   33          172.86             1      45\n",
      "116   62          138.37             0       4\n",
      "117   35          122.30             2      62\n",
      "118   64           36.86             0      65\n",
      "119   70           86.19             0      32\n",
      "\n",
      "[120 rows x 4 columns]\n",
      "Training data y :  (120,)\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "115    0\n",
      "116    0\n",
      "117    0\n",
      "118    0\n",
      "119    1\n",
      "Name: Churn, Length: 120, dtype: int64\n",
      "Validation data x :  (40, 4)\n",
      "     Age  MonthlyCharges  ContractType  Tenure\n",
      "120   41           67.74             0      34\n",
      "121   43           63.92             0      39\n",
      "122   42          195.14             0      26\n",
      "123   77           90.76             1      34\n",
      "124   77          180.57             0      54\n",
      "125   77          133.60             0       3\n",
      "126   62          163.07             2      50\n",
      "127   58          110.47             0      12\n",
      "128   46          123.84             2      65\n",
      "129   32          108.65             1      54\n",
      "130   62           55.14             0       5\n",
      "131   18          150.04             2      57\n",
      "132   42           70.54             2      17\n",
      "133   24           24.38             1      47\n",
      "134   26          136.19             0      23\n",
      "135   41           51.88             0      14\n",
      "136   18          189.28             2      66\n",
      "137   61          191.71             0      51\n",
      "138   25          184.68             2      38\n",
      "139   41           86.63             0      64\n",
      "140   28           22.78             2      38\n",
      "141   68          187.10             0      50\n",
      "142   34           97.07             1      30\n",
      "143   25          194.00             0      51\n",
      "144   52          193.45             0      63\n",
      "145   52          173.54             1      52\n",
      "146   50           73.00             0      38\n",
      "147   76           89.32             1      30\n",
      "148   22          173.20             0      51\n",
      "149   59           77.05             2       5\n",
      "150   56           50.51             2      29\n",
      "151   75          120.22             0       4\n",
      "152   58          188.51             0      10\n",
      "153   45          145.29             0      56\n",
      "154   24          122.61             2      17\n",
      "155   26           37.49             0      17\n",
      "156   25          130.70             2      69\n",
      "157   29          198.21             1      34\n",
      "158   51           45.22             2       6\n",
      "159   50          113.30             2      53\n",
      "Validation data y :  (40,)\n",
      "120    0\n",
      "121    0\n",
      "122    1\n",
      "123    0\n",
      "124    0\n",
      "125    1\n",
      "126    0\n",
      "127    0\n",
      "128    0\n",
      "129    0\n",
      "130    0\n",
      "131    0\n",
      "132    0\n",
      "133    0\n",
      "134    1\n",
      "135    1\n",
      "136    0\n",
      "137    0\n",
      "138    1\n",
      "139    0\n",
      "140    0\n",
      "141    0\n",
      "142    1\n",
      "143    1\n",
      "144    1\n",
      "145    0\n",
      "146    0\n",
      "147    0\n",
      "148    1\n",
      "149    0\n",
      "150    0\n",
      "151    1\n",
      "152    1\n",
      "153    0\n",
      "154    0\n",
      "155    1\n",
      "156    0\n",
      "157    0\n",
      "158    0\n",
      "159    0\n",
      "Name: Churn, dtype: int64\n",
      "Test data x :  (40, 4)\n",
      "     Age  MonthlyCharges  ContractType  Tenure\n",
      "160   65          177.93             1      66\n",
      "161   72          153.34             2      43\n",
      "162   40          145.46             0      23\n",
      "163   79          146.45             0      55\n",
      "164   41           84.71             2      16\n",
      "165   54           72.85             0       8\n",
      "166   52          165.69             2       4\n",
      "167   61          165.82             0       4\n",
      "168   57          176.07             0      56\n",
      "169   39          184.38             2      25\n",
      "170   44          112.04             0      67\n",
      "171   52          110.27             2      67\n",
      "172   18          163.69             0      27\n",
      "173   52          136.99             0      32\n",
      "174   54          146.35             1      50\n",
      "175   64          163.24             1      61\n",
      "176   31          180.20             2      51\n",
      "177   20           80.84             1      19\n",
      "178   18           87.60             2      21\n",
      "179   22           36.92             1       5\n",
      "180   43          124.09             0      42\n",
      "181   72           26.47             2      61\n",
      "182   31          103.81             2      22\n",
      "183   56          117.68             0      21\n",
      "184   44           71.58             2      70\n",
      "185   26          126.35             2       1\n",
      "186   32           25.49             1       5\n",
      "187   32           26.72             2      12\n",
      "188   43          168.07             0      46\n",
      "189   59           84.83             1      34\n",
      "190   77           42.87             1      49\n",
      "191   30          114.00             0      45\n",
      "192   68          158.60             0      27\n",
      "193   49           58.85             1      26\n",
      "194   56          132.12             2      47\n",
      "195   66           35.36             1      56\n",
      "196   69           29.30             0      63\n",
      "197   78          115.64             1      48\n",
      "198   49          117.31             0      61\n",
      "199   21          134.74             1      26\n",
      "Test data y :  (40,)\n",
      "160    1\n",
      "161    0\n",
      "162    1\n",
      "163    0\n",
      "164    0\n",
      "165    1\n",
      "166    1\n",
      "167    0\n",
      "168    0\n",
      "169    0\n",
      "170    0\n",
      "171    0\n",
      "172    0\n",
      "173    1\n",
      "174    0\n",
      "175    0\n",
      "176    0\n",
      "177    0\n",
      "178    0\n",
      "179    0\n",
      "180    1\n",
      "181    0\n",
      "182    0\n",
      "183    1\n",
      "184    0\n",
      "185    0\n",
      "186    0\n",
      "187    0\n",
      "188    0\n",
      "189    0\n",
      "190    1\n",
      "191    0\n",
      "192    0\n",
      "193    0\n",
      "194    0\n",
      "195    0\n",
      "196    0\n",
      "197    0\n",
      "198    0\n",
      "199    1\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(['Churn'], axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "training_split = 0.6\n",
    "validation_split = 0.2\n",
    "test_split = 0.2\n",
    "\n",
    "x_train = x[:int(len(x)*training_split)]\n",
    "y_train = y[:int(len(y)*training_split)]\n",
    "\n",
    "x_val = x[int(len(x)*training_split):int(len(x)*training_split)+int(len(x)*validation_split)]\n",
    "y_val = y[int(len(y)*training_split):int(len(y)*training_split)+int(len(y)*validation_split)]\n",
    "\n",
    "x_test = x[int(len(x)*training_split)+int(len(x)*validation_split):]\n",
    "y_test = y[int(len(y)*training_split)+int(len(y)*validation_split):]\n",
    "\n",
    "print(\"Training data x : \", x_train.shape)\n",
    "print(x_train)\n",
    "print(\"Training data y : \", y_train.shape)\n",
    "print(y_train)\n",
    "\n",
    "print(\"Validation data x : \", x_val.shape)\n",
    "print(x_val)\n",
    "print(\"Validation data y : \", y_val.shape)\n",
    "print(y_val)\n",
    "\n",
    "print(\"Test data x : \", x_test.shape)\n",
    "print(x_test)\n",
    "print(\"Test data y : \", y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Training data x :  (120, 4)\n",
      "          Age  MonthlyCharges  ContractType    Tenure\n",
      "0    0.293785        1.422782     -1.117401 -0.387601\n",
      "1    0.974773       -0.826954      0.147581  1.490218\n",
      "2   -0.230052       -0.276339      0.147581 -1.446884\n",
      "3   -0.963423        0.903305      0.147581 -0.291303\n",
      "4    0.503320       -0.897014      1.412563  0.093891\n",
      "..        ...             ...           ...       ...\n",
      "115 -0.911039        1.223421      0.147581  0.479085\n",
      "116  0.608087        0.568570     -1.117401 -1.495033\n",
      "117 -0.806272        0.263453      1.412563  1.297621\n",
      "118  0.712854       -1.358771     -1.117401  1.442069\n",
      "119  1.027156       -0.422157     -1.117401 -0.146855\n",
      "\n",
      "[120 rows x 4 columns]\n",
      "Normalized Validation data x :  (40, 4)\n",
      "          Age  MonthlyCharges  ContractType    Tenure\n",
      "120 -0.245404       -0.946820     -0.913994 -0.119482\n",
      "121 -0.135110       -1.015673     -0.913994  0.129439\n",
      "122 -0.190257        1.349484     -0.913994 -0.517755\n",
      "123  1.739889       -0.531899      0.193878 -0.119482\n",
      "124  1.739889        1.086869     -0.913994  0.876200\n",
      "125  1.739889        0.240265     -0.913994 -1.662789\n",
      "126  0.912684        0.771443      1.301749  0.677064\n",
      "127  0.692095       -0.176639     -0.913994 -1.214732\n",
      "128  0.030331        0.064347      1.301749  1.423825\n",
      "129 -0.741728       -0.209443      0.193878  0.876200\n",
      "130  0.912684       -1.173927     -0.913994 -1.563221\n",
      "131 -1.513786        0.536585      1.301749  1.025552\n",
      "132 -0.190257       -0.896352      1.301749 -0.965812\n",
      "133 -1.182904       -1.728357      0.193878  0.527711\n",
      "134 -1.072610        0.286948     -0.913994 -0.667107\n",
      "135 -0.245404       -1.232687     -0.913994 -1.115164\n",
      "136 -1.513786        1.243862      1.301749  1.473609\n",
      "137  0.857537        1.287661     -0.913994  0.726848\n",
      "138 -1.127757        1.160950      1.301749  0.079655\n",
      "139 -0.245404       -0.606340     -0.913994  1.374041\n",
      "140 -0.962316       -1.757196      1.301749  0.079655\n",
      "141  1.243566        1.204569     -0.913994  0.677064\n",
      "142 -0.631434       -0.418165      0.193878 -0.318618\n",
      "143 -1.127757        1.328937     -0.913994  0.726848\n",
      "144  0.361213        1.319023     -0.913994  1.324257\n",
      "145  0.361213        0.960158      0.193878  0.776632\n",
      "146  0.250919       -0.852012     -0.913994  0.079655\n",
      "147  1.684742       -0.557854      0.193878 -0.318618\n",
      "148 -1.293198        0.954030     -0.913994  0.726848\n",
      "149  0.747242       -0.779013      1.301749 -1.563221\n",
      "150  0.581801       -1.257380      1.301749 -0.368402\n",
      "151  1.629595       -0.000901     -0.913994 -1.613005\n",
      "152  0.692095        1.229983     -0.913994 -1.314300\n",
      "153 -0.024816        0.450970     -0.913994  0.975768\n",
      "154 -1.182904        0.042177      1.301749 -0.965812\n",
      "155 -1.072610       -1.492057     -0.913994 -0.965812\n",
      "156 -1.127757        0.187994      1.301749  1.622962\n",
      "157 -0.907169        1.404819      0.193878 -0.119482\n",
      "158  0.306066       -1.352729      1.301749 -1.513437\n",
      "159  0.250919       -0.125630      1.301749  0.826416\n",
      "Normalized Test data x :  (40, 4)\n",
      "          Age  MonthlyCharges  ContractType    Tenure\n",
      "160  0.933157        1.315024      0.059115  1.393701\n",
      "161  1.326657        0.819917      1.241422  0.305242\n",
      "162 -0.472200        0.661257     -1.123191 -0.641244\n",
      "163  1.720157        0.681190     -1.123191  0.873133\n",
      "164 -0.415986       -0.561913      1.241422 -0.972515\n",
      "165  0.314800       -0.800708     -1.123191 -1.351109\n",
      "166  0.202371        1.068578      1.241422 -1.540406\n",
      "167  0.708300        1.071195     -1.123191 -1.540406\n",
      "168  0.483443        1.277574     -1.123191  0.920458\n",
      "169 -0.528414        1.444891      1.241422 -0.546596\n",
      "170 -0.247343       -0.011638     -1.123191  1.441025\n",
      "171  0.202371       -0.047276      1.241422  1.441025\n",
      "172 -1.708914        1.028309     -1.123191 -0.451947\n",
      "173  0.202371        0.490718     -1.123191 -0.215326\n",
      "174  0.314800        0.679177      0.059115  0.636512\n",
      "175  0.876943        1.019248      0.059115  1.157079\n",
      "176 -0.978128        1.360729      1.241422  0.683836\n",
      "177 -1.596485       -0.639834      0.059115 -0.830542\n",
      "178 -1.708914       -0.503725      1.241422 -0.735893\n",
      "179 -1.484057       -1.524141      0.059115 -1.493082\n",
      "180 -0.303557        0.230983     -1.123191  0.257917\n",
      "181  1.326657       -1.734546      1.241422  1.157079\n",
      "182 -0.978128       -0.177345      1.241422 -0.688569\n",
      "183  0.427228        0.101921     -1.123191 -0.735893\n",
      "184 -0.247343       -0.826279      1.241422  1.582998\n",
      "185 -1.259200        0.276487      1.241422 -1.682379\n",
      "186 -0.921914       -1.754278      0.059115 -1.493082\n",
      "187 -0.921914       -1.729513      1.241422 -1.161812\n",
      "188 -0.303557        1.116498     -1.123191  0.447215\n",
      "189  0.595871       -0.559497      0.059115 -0.120677\n",
      "190  1.607728       -1.404341      0.059115  0.589188\n",
      "191 -1.034343        0.027826     -1.123191  0.399890\n",
      "192  1.101800        0.925824     -1.123191 -0.451947\n",
      "193  0.033729       -1.082591      0.059115 -0.499271\n",
      "194  0.427228        0.392663      1.241422  0.494539\n",
      "195  0.989371       -1.555551      0.059115  0.920458\n",
      "196  1.158014       -1.677566     -1.123191  1.251728\n",
      "197  1.663942        0.060846      0.059115  0.541863\n",
      "198  0.033729        0.094471     -1.123191  1.157079\n",
      "199 -1.540271        0.445415      0.059115 -0.499271\n"
     ]
    }
   ],
   "source": [
    "x_train = (x_train - x_train.mean()) / x_train.std()\n",
    "x_val = (x_val - x_val.mean()) / x_val.std()\n",
    "x_test = (x_test - x_test.mean()) / x_test.std()\n",
    "\n",
    "print(\"Normalized Training data x : \", x_train.shape)\n",
    "print(x_train)\n",
    "print(\"Normalized Validation data x : \", x_val.shape)\n",
    "print(x_val)\n",
    "print(\"Normalized Test data x : \", x_test.shape)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the initial parameters\n",
    "and using the validation set to set alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOG LOSS\n",
    "\n",
    "def logLoss(y, y_pred):\n",
    "    return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights :  [0.5488135  0.71518937 0.60276338 0.54488318]\n",
      "Initial bias :  [0.4236548]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "w = np.random.rand(x_train.shape[1])\n",
    "b = np.random.rand(1)\n",
    "print(\"Initial weights : \", w)\n",
    "print(\"Initial bias : \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using gradient descent to minimize the cost function with respect to the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha :  0.1\n",
      "Best validation error :  0.3437291704358101\n"
     ]
    }
   ],
   "source": [
    "best_alpha = None\n",
    "best_val_error = float('inf')\n",
    "epochs = 1000   \n",
    "possible_alphas = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "for alpha in possible_alphas:\n",
    "    for epoch in range(epochs):\n",
    "        z = np.dot(x_train, w) + b\n",
    "        y_pred = sigmoid(z)\n",
    "        error = y_train - y_pred\n",
    "        w = w + alpha * np.dot(x_train.T, error) / len(x_train)\n",
    "        b = b + alpha * np.mean(error)\n",
    "        \n",
    "        z_val = np.dot(x_val, w) + b\n",
    "        y_pred_val = sigmoid(z_val)\n",
    "        val_error = np.mean(np.abs(y_val - y_pred_val))\n",
    "        \n",
    "        if val_error < best_val_error:\n",
    "            best_val_error = val_error\n",
    "            best_alpha = alpha\n",
    "            \n",
    "print(\"Best alpha : \", best_alpha)\n",
    "print(\"Best validation error : \", best_val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z (test set): [-1.49199622 -1.36525857 -0.03986745 -0.94012707 -1.00150423 -0.01759316\n",
      " -0.16905464  0.64880606 -0.8114227  -0.68161303 -1.51680699 -2.33218139\n",
      " -0.06543924 -0.34358718 -1.21794003 -1.43286625 -1.47051233 -0.72131476\n",
      " -1.14684303 -0.56867023 -0.71738343 -2.63383151 -1.07180432 -0.13287889\n",
      " -2.65209461 -0.33049353 -0.62852184 -1.23093367 -0.57643896 -1.10791321\n",
      " -1.77866437 -0.87329207 -0.05968782 -1.0337879  -1.61769154 -2.0347602\n",
      " -1.86705241 -1.32242613 -1.30728507 -0.60908384]\n",
      "Sigmoid (test set): [0.1836223  0.20338698 0.49003446 0.28087467 0.26864577 0.49560182\n",
      " 0.45783671 0.65674136 0.30758741 0.33590139 0.17993219 0.08849255\n",
      " 0.48364602 0.41493837 0.22829917 0.19265248 0.18686475 0.32710353\n",
      " 0.24106619 0.36154372 0.32796943 0.06699257 0.2550601  0.46682907\n",
      " 0.06586003 0.41812054 0.34784578 0.22601805 0.3597524  0.24826013\n",
      " 0.14446814 0.29456975 0.48508247 0.2623504  0.16552348 0.11560136\n",
      " 0.13388315 0.21041493 0.21294151 0.35226821]\n",
      "Actual (test set): 160    1\n",
      "161    0\n",
      "162    1\n",
      "163    0\n",
      "164    0\n",
      "165    1\n",
      "166    1\n",
      "167    0\n",
      "168    0\n",
      "169    0\n",
      "170    0\n",
      "171    0\n",
      "172    0\n",
      "173    1\n",
      "174    0\n",
      "175    0\n",
      "176    0\n",
      "177    0\n",
      "178    0\n",
      "179    0\n",
      "180    1\n",
      "181    0\n",
      "182    0\n",
      "183    1\n",
      "184    0\n",
      "185    0\n",
      "186    0\n",
      "187    0\n",
      "188    0\n",
      "189    0\n",
      "190    1\n",
      "191    0\n",
      "192    0\n",
      "193    0\n",
      "194    0\n",
      "195    0\n",
      "196    0\n",
      "197    0\n",
      "198    0\n",
      "199    1\n",
      "Name: Churn, dtype: int64\n",
      "Predicted (test set): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Error (test set): 0.25\n",
      "Confusion matrix:\n",
      "[[30  1]\n",
      " [ 9  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_386846/1856113630.py:9: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2 * (precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model performance\n",
    "z_test = np.dot(x_test, w) + b\n",
    "y_pred_test = sigmoid(z_test)\n",
    "y_pred_test_binary = np.round(y_pred_test)\n",
    "\n",
    "accuracy = np.mean(y_test == y_pred_test_binary)\n",
    "precision = np.sum(y_pred_test_binary[y_test == 1] == 1) / np.sum(y_pred_test_binary == 1)\n",
    "recall = np.sum(y_pred_test_binary[y_test == 1] == 1) / np.sum(y_test == 1)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Z (test set):\", z_test)\n",
    "print(\"Sigmoid (test set):\", y_pred_test)\n",
    "print(\"Actual (test set):\", y_test)\n",
    "print(\"Predicted (test set):\", y_pred_test_binary)\n",
    "print(\"Error (test set):\", np.mean(np.abs(y_test - y_pred_test_binary)))\n",
    "\n",
    "confusion_matrix = np.zeros((2, 2), dtype=int)\n",
    "for i in range(len(y_test)):\n",
    "    confusion_matrix[int(y_test.iloc[i])][int(y_pred_test_binary[i])] += 1\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before modifying the dataset :\n",
      "   Age  MonthlyCharges ContractType  Tenure        ChurnType\n",
      "0   56          183.36      Monthly      27  Voluntary Churn\n",
      "1   69           64.87     One year      66         No Churn\n",
      "2   46           93.87     One year       5  Voluntary Churn\n",
      "3   32          156.00     One year      29  Voluntary Churn\n",
      "\n",
      "After modifying the dataset :\n",
      "   Age  MonthlyCharges  ContractType  Tenure  ChurnType\n",
      "0   56          183.36             0      27          2\n",
      "1   69           64.87             1      66          0\n",
      "2   46           93.87             1       5          2\n",
      "3   32          156.00             1      29          2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"customer_churn_dataset2.csv\")\n",
    "print(\"Before modifying the dataset :\")\n",
    "print(df.head(4))\n",
    "print()\n",
    "df['ContractType'] = df['ContractType'].map({'Monthly': 0, 'One year': 1, 'Two year': 2})\n",
    "df['ChurnType'] = df['ChurnType'].map({'Voluntary Churn': 2, 'Involuntary Churn': 1, 'No Churn': 0})\n",
    "print(\"After modifying the dataset :\")\n",
    "print(df.head(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset to Training, Testing and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data x :  (120, 4)\n",
      "[[ 56.   183.36   0.    27.  ]\n",
      " [ 69.    64.87   1.    66.  ]\n",
      " [ 46.    93.87   1.     5.  ]\n",
      " [ 32.   156.     1.    29.  ]\n",
      " [ 60.    61.18   2.    37.  ]\n",
      " [ 25.    33.86   0.    38.  ]\n",
      " [ 78.    72.16   2.     8.  ]\n",
      " [ 38.    49.02   2.    65.  ]\n",
      " [ 56.   187.35   1.    17.  ]\n",
      " [ 75.   165.46   2.    71.  ]\n",
      " [ 36.   134.01   1.    45.  ]\n",
      " [ 40.   176.86   0.     4.  ]\n",
      " [ 28.   164.66   1.    36.  ]\n",
      " [ 28.    53.58   0.    70.  ]\n",
      " [ 41.   180.66   1.    31.  ]\n",
      " [ 70.   117.08   2.    19.  ]\n",
      " [ 53.   165.34   2.    61.  ]\n",
      " [ 57.   181.3    0.    54.  ]\n",
      " [ 41.    77.24   0.    39.  ]\n",
      " [ 20.    39.81   0.    19.  ]\n",
      " [ 39.    61.03   1.    39.  ]\n",
      " [ 70.    96.88   1.    67.  ]\n",
      " [ 19.   167.24   0.    45.  ]\n",
      " [ 41.   174.93   2.    13.  ]\n",
      " [ 61.    21.25   1.    58.  ]\n",
      " [ 47.   111.93   1.    20.  ]\n",
      " [ 55.    95.13   1.    61.  ]\n",
      " [ 19.    59.98   0.    39.  ]\n",
      " [ 77.    41.58   0.     1.  ]\n",
      " [ 38.    80.77   0.     3.  ]\n",
      " [ 50.   189.72   0.    62.  ]\n",
      " [ 29.    78.18   0.    63.  ]\n",
      " [ 75.   113.38   2.    25.  ]\n",
      " [ 39.   146.54   2.    56.  ]\n",
      " [ 78.    85.45   0.    33.  ]\n",
      " [ 61.   194.92   1.    38.  ]\n",
      " [ 42.   193.24   0.     6.  ]\n",
      " [ 66.    65.32   2.    58.  ]\n",
      " [ 44.   109.5    2.    44.  ]\n",
      " [ 76.    74.16   1.    45.  ]\n",
      " [ 59.    71.27   2.    32.  ]\n",
      " [ 45.    26.64   0.    45.  ]\n",
      " [ 77.   129.72   1.    61.  ]\n",
      " [ 33.   110.48   0.    47.  ]\n",
      " [ 32.    29.27   0.    21.  ]\n",
      " [ 79.    70.16   1.    36.  ]\n",
      " [ 79.   183.49   0.    19.  ]\n",
      " [ 64.    63.12   2.    20.  ]\n",
      " [ 79.    46.08   0.    57.  ]\n",
      " [ 68.   108.1    1.    18.  ]\n",
      " [ 61.   197.42   1.    47.  ]\n",
      " [ 72.    63.57   1.    49.  ]\n",
      " [ 69.   140.98   0.    14.  ]\n",
      " [ 74.   157.09   1.    15.  ]\n",
      " [ 20.    62.77   1.    31.  ]\n",
      " [ 54.   151.08   0.     1.  ]\n",
      " [ 68.    86.2    2.    54.  ]\n",
      " [ 24.   133.82   0.     3.  ]\n",
      " [ 38.   134.04   1.    16.  ]\n",
      " [ 26.   116.44   1.    57.  ]\n",
      " [ 56.    36.25   0.    12.  ]\n",
      " [ 35.   170.35   2.    16.  ]\n",
      " [ 21.    77.74   1.    24.  ]\n",
      " [ 42.    53.57   1.    28.  ]\n",
      " [ 77.    27.34   1.     8.  ]\n",
      " [ 31.   126.36   0.    36.  ]\n",
      " [ 67.   141.96   1.     8.  ]\n",
      " [ 75.    22.99   2.    58.  ]\n",
      " [ 26.   112.18   1.    60.  ]\n",
      " [ 43.    60.77   1.    50.  ]\n",
      " [ 70.   136.13   2.    28.  ]\n",
      " [ 19.    51.39   1.    41.  ]\n",
      " [ 37.   144.37   0.    64.  ]\n",
      " [ 45.    89.61   0.    27.  ]\n",
      " [ 64.   188.61   0.    63.  ]\n",
      " [ 77.    44.75   2.    17.  ]\n",
      " [ 24.    81.39   1.    33.  ]\n",
      " [ 61.    40.43   0.    29.  ]\n",
      " [ 78.   186.44   2.    13.  ]\n",
      " [ 25.   177.92   1.    46.  ]\n",
      " [ 64.    66.43   2.    35.  ]\n",
      " [ 52.   138.8    0.     6.  ]\n",
      " [ 31.   167.1    0.    69.  ]\n",
      " [ 34.   119.94   0.    47.  ]\n",
      " [ 53.   115.34   2.    25.  ]\n",
      " [ 67.    63.53   2.    66.  ]\n",
      " [ 57.    36.76   0.    10.  ]\n",
      " [ 21.   181.5    2.    56.  ]\n",
      " [ 19.   182.08   0.    30.  ]\n",
      " [ 79.   133.96   0.     5.  ]\n",
      " [ 23.    81.03   1.    33.  ]\n",
      " [ 71.    82.86   2.    65.  ]\n",
      " [ 59.   150.67   0.    18.  ]\n",
      " [ 21.   181.48   0.    49.  ]\n",
      " [ 71.   179.68   2.    11.  ]\n",
      " [ 46.   160.38   1.    26.  ]\n",
      " [ 35.   135.57   1.    63.  ]\n",
      " [ 43.    35.15   0.    59.  ]\n",
      " [ 61.    49.09   2.    27.  ]\n",
      " [ 51.   181.74   1.    49.  ]\n",
      " [ 27.   129.16   2.    33.  ]\n",
      " [ 79.    21.66   2.     1.  ]\n",
      " [ 53.    38.26   0.    21.  ]\n",
      " [ 31.   139.43   1.    55.  ]\n",
      " [ 48.    20.91   0.     6.  ]\n",
      " [ 65.    48.95   1.    69.  ]\n",
      " [ 32.   118.77   1.     5.  ]\n",
      " [ 25.   144.54   1.     3.  ]\n",
      " [ 31.   137.35   1.    53.  ]\n",
      " [ 40.    60.37   1.    23.  ]\n",
      " [ 77.   148.19   2.    53.  ]\n",
      " [ 74.    62.7    0.    37.  ]\n",
      " [ 79.    78.57   2.    17.  ]\n",
      " [ 57.   154.37   1.     1.  ]\n",
      " [ 38.   136.93   0.    51.  ]\n",
      " [ 33.   172.86   1.    45.  ]\n",
      " [ 62.   138.37   0.     4.  ]\n",
      " [ 35.   122.3    2.    62.  ]\n",
      " [ 64.    36.86   0.    65.  ]\n",
      " [ 70.    86.19   0.    32.  ]]\n",
      "Training data y :  (120,)\n",
      "[2 0 2 2 0 2 2 0 2 0 0 1 2 2 2 2 0 2 0 2 0 0 2 0 0 2 0 2 2 2 2 2 2 0 2 0 1\n",
      " 0 0 0 0 0 0 2 2 0 2 0 0 2 0 0 2 2 0 1 0 1 2 0 2 0 0 0 2 2 2 0 0 0 2 0 2 2\n",
      " 2 0 0 2 2 0 0 1 2 2 0 0 2 0 2 1 0 0 2 2 2 2 0 0 0 0 2 2 2 0 2 0 2 2 0 0 0\n",
      " 0 0 2 2 0 1 0 0 2]\n",
      "Validation data x :  (40, 4)\n",
      "[[ 41.    67.74   0.    34.  ]\n",
      " [ 43.    63.92   0.    39.  ]\n",
      " [ 42.   195.14   0.    26.  ]\n",
      " [ 77.    90.76   1.    34.  ]\n",
      " [ 77.   180.57   0.    54.  ]\n",
      " [ 77.   133.6    0.     3.  ]\n",
      " [ 62.   163.07   2.    50.  ]\n",
      " [ 58.   110.47   0.    12.  ]\n",
      " [ 46.   123.84   2.    65.  ]\n",
      " [ 32.   108.65   1.    54.  ]\n",
      " [ 62.    55.14   0.     5.  ]\n",
      " [ 18.   150.04   2.    57.  ]\n",
      " [ 42.    70.54   2.    17.  ]\n",
      " [ 24.    24.38   1.    47.  ]\n",
      " [ 26.   136.19   0.    23.  ]\n",
      " [ 41.    51.88   0.    14.  ]\n",
      " [ 18.   189.28   2.    66.  ]\n",
      " [ 61.   191.71   0.    51.  ]\n",
      " [ 25.   184.68   2.    38.  ]\n",
      " [ 41.    86.63   0.    64.  ]\n",
      " [ 28.    22.78   2.    38.  ]\n",
      " [ 68.   187.1    0.    50.  ]\n",
      " [ 34.    97.07   1.    30.  ]\n",
      " [ 25.   194.     0.    51.  ]\n",
      " [ 52.   193.45   0.    63.  ]\n",
      " [ 52.   173.54   1.    52.  ]\n",
      " [ 50.    73.     0.    38.  ]\n",
      " [ 76.    89.32   1.    30.  ]\n",
      " [ 22.   173.2    0.    51.  ]\n",
      " [ 59.    77.05   2.     5.  ]\n",
      " [ 56.    50.51   2.    29.  ]\n",
      " [ 75.   120.22   0.     4.  ]\n",
      " [ 58.   188.51   0.    10.  ]\n",
      " [ 45.   145.29   0.    56.  ]\n",
      " [ 24.   122.61   2.    17.  ]\n",
      " [ 26.    37.49   0.    17.  ]\n",
      " [ 25.   130.7    2.    69.  ]\n",
      " [ 29.   198.21   1.    34.  ]\n",
      " [ 51.    45.22   2.     6.  ]\n",
      " [ 50.   113.3    2.    53.  ]]\n",
      "Validation data y :  (40,)\n",
      "[2 0 2 0 2 1 0 2 0 0 2 0 0 0 2 2 0 2 0 0 0 2 0 2 2 0 0 0 2 0 0 1 1 2 2 2 0\n",
      " 2 0 0]\n",
      "Test data x :  (40, 4)\n",
      "[[ 65.   177.93   1.    66.  ]\n",
      " [ 72.   153.34   2.    43.  ]\n",
      " [ 40.   145.46   0.    23.  ]\n",
      " [ 79.   146.45   0.    55.  ]\n",
      " [ 41.    84.71   2.    16.  ]\n",
      " [ 54.    72.85   0.     8.  ]\n",
      " [ 52.   165.69   2.     4.  ]\n",
      " [ 61.   165.82   0.     4.  ]\n",
      " [ 57.   176.07   0.    56.  ]\n",
      " [ 39.   184.38   2.    25.  ]\n",
      " [ 44.   112.04   0.    67.  ]\n",
      " [ 52.   110.27   2.    67.  ]\n",
      " [ 18.   163.69   0.    27.  ]\n",
      " [ 52.   136.99   0.    32.  ]\n",
      " [ 54.   146.35   1.    50.  ]\n",
      " [ 64.   163.24   1.    61.  ]\n",
      " [ 31.   180.2    2.    51.  ]\n",
      " [ 20.    80.84   1.    19.  ]\n",
      " [ 18.    87.6    2.    21.  ]\n",
      " [ 22.    36.92   1.     5.  ]\n",
      " [ 43.   124.09   0.    42.  ]\n",
      " [ 72.    26.47   2.    61.  ]\n",
      " [ 31.   103.81   2.    22.  ]\n",
      " [ 56.   117.68   0.    21.  ]\n",
      " [ 44.    71.58   2.    70.  ]\n",
      " [ 26.   126.35   2.     1.  ]\n",
      " [ 32.    25.49   1.     5.  ]\n",
      " [ 32.    26.72   2.    12.  ]\n",
      " [ 43.   168.07   0.    46.  ]\n",
      " [ 59.    84.83   1.    34.  ]\n",
      " [ 77.    42.87   1.    49.  ]\n",
      " [ 30.   114.     0.    45.  ]\n",
      " [ 68.   158.6    0.    27.  ]\n",
      " [ 49.    58.85   1.    26.  ]\n",
      " [ 56.   132.12   2.    47.  ]\n",
      " [ 66.    35.36   1.    56.  ]\n",
      " [ 69.    29.3    0.    63.  ]\n",
      " [ 78.   115.64   1.    48.  ]\n",
      " [ 49.   117.31   0.    61.  ]\n",
      " [ 21.   134.74   1.    26.  ]]\n",
      "Test data y :  (40,)\n",
      "[0 0 2 2 0 2 2 1 2 0 2 0 2 2 0 0 0 0 0 2 2 0 0 2 0 2 2 0 2 0 0 2 2 0 0 0 0\n",
      " 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(['ChurnType'], axis=1)\n",
    "y = df['ChurnType']\n",
    "\n",
    "training_split = 0.6\n",
    "validation_split = 0.2\n",
    "test_split = 0.2\n",
    "\n",
    "x_train = x[:int(len(x)*training_split)]\n",
    "y_train = y[:int(len(y)*training_split)]\n",
    "\n",
    "x_val = x[int(len(x)*training_split):int(len(x)*training_split)+int(len(x)*validation_split)]\n",
    "y_val = y[int(len(y)*training_split):int(len(y)*training_split)+int(len(y)*validation_split)]\n",
    "\n",
    "x_test = x[int(len(x)*training_split)+int(len(x)*validation_split):]\n",
    "y_test = y[int(len(y)*training_split)+int(len(y)*validation_split):]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"Training data x : \", x_train.shape)\n",
    "print(x_train)\n",
    "print(\"Training data y : \", y_train.shape)\n",
    "print(y_train)\n",
    "\n",
    "print(\"Validation data x : \", x_val.shape)\n",
    "print(x_val)\n",
    "print(\"Validation data y : \", y_val.shape)\n",
    "print(y_val)\n",
    "\n",
    "print(\"Test data x : \", x_test.shape)\n",
    "print(x_test)\n",
    "print(\"Test data y : \", y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Training data x :  (120, 4)\n",
      "[[ 0.14939985  2.75140074 -0.99469602 -0.44307837]\n",
      " [ 0.41499354  0.33061647 -0.97426573  0.35370269]\n",
      " [-0.05490298  0.92309468 -0.97426573 -0.8925446 ]\n",
      " [-0.34092695  2.19242819 -0.97426573 -0.4022178 ]\n",
      " [ 0.23112099  0.25522872 -0.95383545 -0.23877553]\n",
      " [-0.48393893 -0.30292662 -0.99469602 -0.21834525]\n",
      " [ 0.59886609  0.47955323 -0.95383545 -0.83125375]\n",
      " [-0.21834525  0.00679647 -0.95383545  0.3332724 ]\n",
      " [ 0.14939985  2.83291757 -0.97426573 -0.6473812 ]\n",
      " [ 0.53757524  2.38569867 -0.95383545  0.4558541 ]\n",
      " [-0.25920581  1.74316626 -0.97426573 -0.07533326]\n",
      " [-0.17748468  2.6186039  -0.99469602 -0.91297488]\n",
      " [-0.42264808  2.36935444 -0.97426573 -0.25920581]\n",
      " [-0.42264808  0.09995857 -0.99469602  0.43542382]\n",
      " [-0.1570544   2.69623897 -0.97426573 -0.36135723]\n",
      " [ 0.43542382  1.39728156 -0.95383545 -0.60652063]\n",
      " [ 0.088109    2.38324703 -0.95383545  0.25155127]\n",
      " [ 0.16983014  2.70931436 -0.99469602  0.10853929]\n",
      " [-0.1570544   0.58333907 -0.99469602 -0.19791496]\n",
      " [-0.58609035 -0.18136644 -0.99469602 -0.60652063]\n",
      " [-0.19791496  0.25216418 -0.97426573 -0.19791496]\n",
      " [ 0.43542382  0.98458984 -0.97426573  0.37413297]\n",
      " [-0.60652063  2.42206457 -0.99469602 -0.07533326]\n",
      " [-0.1570544   2.57917345 -0.95383545 -0.72910233]\n",
      " [ 0.25155127 -0.56055249 -0.97426573  0.19026042]\n",
      " [-0.0344727   1.2920656  -0.97426573 -0.58609035]\n",
      " [ 0.12896957  0.94883684 -0.97426573  0.25155127]\n",
      " [-0.60652063  0.23071238 -0.99469602 -0.19791496]\n",
      " [ 0.5784358  -0.14520483 -0.99469602 -0.97426573]\n",
      " [-0.21834525  0.65545797 -0.99469602 -0.93340517]\n",
      " [ 0.02681815  2.88133734 -0.99469602  0.27198155]\n",
      " [-0.4022178   0.60254354 -0.99469602  0.29241184]\n",
      " [ 0.53757524  1.32168951 -0.95383545 -0.48393893]\n",
      " [-0.19791496  1.99915771 -0.95383545  0.14939985]\n",
      " [ 0.59886609  0.7510717  -0.99469602 -0.32049666]\n",
      " [ 0.25155127  2.98757481 -0.97426573 -0.21834525]\n",
      " [-0.13662411  2.95325194 -0.99469602 -0.87211432]\n",
      " [ 0.35370269  0.33981009 -0.95383545  0.19026042]\n",
      " [-0.09576355  1.24242001 -0.95383545 -0.09576355]\n",
      " [ 0.55800552  0.5204138  -0.97426573 -0.07533326]\n",
      " [ 0.2106907   0.46137028 -0.95383545 -0.34092695]\n",
      " [-0.07533326 -0.45043327 -0.99469602 -0.07533326]\n",
      " [ 0.5784358   1.65552034 -0.97426573  0.25155127]\n",
      " [-0.32049666  1.26244169 -0.99469602 -0.0344727 ]\n",
      " [-0.34092695 -0.39670162 -0.99469602 -0.56566007]\n",
      " [ 0.61929637  0.43869266 -0.97426573 -0.25920581]\n",
      " [ 0.61929637  2.75405668 -0.99469602 -0.60652063]\n",
      " [ 0.31284212  0.29486347 -0.95383545 -0.58609035]\n",
      " [ 0.61929637 -0.05326856 -0.99469602  0.16983014]\n",
      " [ 0.39456325  1.21381761 -0.97426573 -0.62695092]\n",
      " [ 0.25155127  3.03865052 -0.97426573 -0.0344727 ]\n",
      " [ 0.47628439  0.3040571  -0.97426573  0.00638787]\n",
      " [ 0.41499354  1.88556533 -0.99469602 -0.70867205]\n",
      " [ 0.51714495  2.2146972  -0.97426573 -0.68824177]\n",
      " [-0.58609035  0.28771287 -0.97426573 -0.36135723]\n",
      " [ 0.10853929  2.09191119 -0.99469602 -0.97426573]\n",
      " [ 0.39456325  0.76639441 -0.95383545  0.10853929]\n",
      " [-0.50436922  1.7392845  -0.99469602 -0.93340517]\n",
      " [-0.21834525  1.74377916 -0.97426573 -0.66781148]\n",
      " [-0.46350865  1.38420618 -0.97426573  0.16983014]\n",
      " [ 0.14939985 -0.25409824 -0.99469602 -0.74953262]\n",
      " [-0.2796361   2.48560275 -0.95383545 -0.66781148]\n",
      " [-0.56566007  0.59355421 -0.97426573 -0.50436922]\n",
      " [-0.13662411  0.09975426 -0.97426573 -0.42264808]\n",
      " [ 0.5784358  -0.43613207 -0.97426573 -0.83125375]\n",
      " [-0.36135723  1.58687459 -0.99469602 -0.25920581]\n",
      " [ 0.37413297  1.90558701 -0.97426573 -0.83125375]\n",
      " [ 0.53757524 -0.5250038  -0.95383545  0.19026042]\n",
      " [-0.46350865  1.29717317 -0.97426573  0.23112099]\n",
      " [-0.11619383  0.2468523  -0.97426573  0.02681815]\n",
      " [ 0.43542382  1.78647846 -0.95383545 -0.42264808]\n",
      " [-0.60652063  0.05521625 -0.97426573 -0.1570544 ]\n",
      " [-0.23877553  1.95482399 -0.99469602  0.31284212]\n",
      " [-0.07533326  0.83606168 -0.99469602 -0.44307837]\n",
      " [ 0.31284212  2.85865973 -0.99469602  0.29241184]\n",
      " [ 0.5784358  -0.08044084 -0.95383545 -0.6473812 ]\n",
      " [-0.50436922  0.66812475 -0.97426573 -0.32049666]\n",
      " [ 0.25155127 -0.16869966 -0.99469602 -0.4022178 ]\n",
      " [ 0.59886609  2.81432601 -0.95383545 -0.72910233]\n",
      " [-0.48393893  2.64026    -0.97426573 -0.05490298]\n",
      " [ 0.31284212  0.36248771 -0.95383545 -0.2796361 ]\n",
      " [ 0.06767872  1.84102731 -0.99469602 -0.87211432]\n",
      " [-0.36135723  2.41920433 -0.99469602  0.41499354]\n",
      " [-0.30006638  1.45571217 -0.99469602 -0.0344727 ]\n",
      " [ 0.088109    1.36173287 -0.95383545 -0.48393893]\n",
      " [ 0.37413297  0.30323989 -0.95383545  0.35370269]\n",
      " [ 0.16983014 -0.2436788  -0.99469602 -0.79039318]\n",
      " [-0.56566007  2.71340041 -0.95383545  0.14939985]\n",
      " [-0.60652063  2.72524998 -0.99469602 -0.38178751]\n",
      " [ 0.61929637  1.74214474 -0.99469602 -0.8925446 ]\n",
      " [-0.5247995   0.66076984 -0.97426573 -0.32049666]\n",
      " [ 0.4558541   0.69815726 -0.95383545  0.3332724 ]\n",
      " [ 0.2106907   2.08353478 -0.99469602 -0.62695092]\n",
      " [-0.56566007  2.71299181 -0.99469602  0.00638787]\n",
      " [ 0.4558541   2.6762173  -0.95383545 -0.7699629 ]\n",
      " [-0.05490298  2.28191283 -0.97426573 -0.46350865]\n",
      " [-0.2796361   1.7750375  -0.97426573  0.29241184]\n",
      " [-0.11619383 -0.27657156 -0.99469602  0.2106907 ]\n",
      " [ 0.25155127  0.00822659 -0.95383545 -0.44307837]\n",
      " [ 0.04724844  2.71830368 -0.97426573  0.00638787]\n",
      " [-0.44307837  1.64407938 -0.95383545 -0.32049666]\n",
      " [ 0.61929637 -0.55217608 -0.95383545 -0.97426573]\n",
      " [ 0.088109   -0.21303337 -0.99469602 -0.56566007]\n",
      " [-0.36135723  1.85389839 -0.97426573  0.12896957]\n",
      " [-0.01404241 -0.56749879 -0.99469602 -0.87211432]\n",
      " [ 0.3332724   0.00536635 -0.97426573  0.41499354]\n",
      " [-0.34092695  1.43180874 -0.97426573 -0.8925446 ]\n",
      " [-0.48393893  1.95829714 -0.97426573 -0.93340517]\n",
      " [-0.36135723  1.8114034  -0.97426573  0.088109  ]\n",
      " [-0.17748468  0.23868019 -0.97426573 -0.5247995 ]\n",
      " [ 0.5784358   2.03286767 -0.95383545  0.088109  ]\n",
      " [ 0.51714495  0.28628275 -0.99469602 -0.23877553]\n",
      " [ 0.61929637  0.61051135 -0.95383545 -0.6473812 ]\n",
      " [ 0.16983014  2.15912682 -0.97426573 -0.97426573]\n",
      " [-0.21834525  1.80282268 -0.99469602  0.04724844]\n",
      " [-0.32049666  2.53688276 -0.97426573 -0.07533326]\n",
      " [ 0.27198155  1.83224229 -0.99469602 -0.91297488]\n",
      " [-0.2796361   1.50392764 -0.95383545  0.27198155]\n",
      " [ 0.31284212 -0.24163577 -0.99469602  0.3332724 ]\n",
      " [ 0.43542382  0.76619011 -0.99469602 -0.34092695]]\n",
      "Normalized Validation data x :  (40, 4)\n",
      "[[-0.18338112  0.32026363 -0.95561129 -0.31522529]\n",
      " [-0.14571136  0.24831438 -0.95561129 -0.22105088]\n",
      " [-0.16454624  2.7198276  -0.95561129 -0.46590435]\n",
      " [ 0.49467463  0.75384261 -0.9367764  -0.31522529]\n",
      " [ 0.49467463  2.44540337 -0.95561129  0.06147235]\n",
      " [ 0.49467463  1.56072896 -0.95561129 -0.89910664]\n",
      " [ 0.2121514   2.11579293 -0.91794152 -0.01386718]\n",
      " [ 0.13681187  1.12507814 -0.95561129 -0.7295927 ]\n",
      " [-0.08920671  1.37690051 -0.91794152  0.26865605]\n",
      " [-0.35289506  1.09079865 -0.9367764   0.06147235]\n",
      " [ 0.2121514   0.08294411 -0.95561129 -0.86143687]\n",
      " [-0.61658341  1.87037442 -0.91794152  0.11797699]\n",
      " [-0.16454624  0.3730013  -0.91794152 -0.63541829]\n",
      " [-0.50357412 -0.49641686 -0.9367764  -0.07037183]\n",
      " [-0.46590435  1.6095113  -0.95561129 -0.522409  ]\n",
      " [-0.18338112  0.0215424  -0.95561129 -0.69192294]\n",
      " [-0.61658341  2.60945519 -0.91794152  0.28749093]\n",
      " [ 0.19331652  2.65522396 -0.95561129  0.0049677 ]\n",
      " [-0.48473923  2.52281473 -0.91794152 -0.23988577]\n",
      " [-0.18338112  0.67605455 -0.95561129  0.24982117]\n",
      " [-0.42823459 -0.52655267 -0.91794152 -0.23988577]\n",
      " [ 0.3251607   2.56839515 -0.95561129 -0.01386718]\n",
      " [-0.31522529  0.87269072 -0.9367764  -0.39056482]\n",
      " [-0.48473923  2.69835584 -0.95561129  0.0049677 ]\n",
      " [ 0.02380258  2.68799665 -0.95561129  0.23098628]\n",
      " [ 0.02380258  2.31299415 -0.9367764   0.02380258]\n",
      " [-0.01386718  0.41933511 -0.95561129 -0.23988577]\n",
      " [ 0.47583975  0.72672038 -0.9367764  -0.39056482]\n",
      " [-0.54124388  2.30659029 -0.95561129  0.0049677 ]\n",
      " [ 0.15564676  0.49561638 -0.91794152 -0.86143687]\n",
      " [ 0.09914211 -0.00426139 -0.91794152 -0.40939971]\n",
      " [ 0.45700487  1.30871824 -0.95561129 -0.88027176]\n",
      " [ 0.13681187  2.59495233 -0.95561129 -0.76726246]\n",
      " [-0.10804159  1.78090873 -0.95561129  0.09914211]\n",
      " [-0.50357412  1.3537336  -0.91794152 -0.63541829]\n",
      " [-0.46590435 -0.24949156 -0.95561129 -0.63541829]\n",
      " [-0.48473923  1.5061078  -0.91794152  0.34399558]\n",
      " [-0.40939971  2.77765069 -0.9367764  -0.31522529]\n",
      " [ 0.0049677  -0.10389792 -0.91794152 -0.84260199]\n",
      " [-0.01386718  1.17838085 -0.91794152  0.04263746]]\n",
      "Normalized Test data x :  (40, 4)\n",
      "[[ 0.31278186  2.61084998 -0.98958561  0.33313136]\n",
      " [ 0.45522831  2.11045598 -0.96923612 -0.13490696]\n",
      " [-0.19595543  1.95010198 -1.00993511 -0.54189679]\n",
      " [ 0.59767475  1.97024798 -1.00993511  0.10928695]\n",
      " [-0.17560594  0.71387035 -0.96923612 -0.68434324]\n",
      " [ 0.08893745  0.47252538 -1.00993511 -0.84713917]\n",
      " [ 0.04823847  2.3617722  -0.96923612 -0.92853714]\n",
      " [ 0.2313839   2.36441763 -1.00993511 -0.92853714]\n",
      " [ 0.14998593  2.57299993 -1.00993511  0.12963644]\n",
      " [-0.21630492  2.7421042  -0.96923612 -0.50119781]\n",
      " [-0.11455746  1.27002196 -1.00993511  0.35348085]\n",
      " [ 0.04823847  1.23400336 -0.96923612  0.35348085]\n",
      " [-0.64364425  2.32107322 -1.00993511 -0.46049883]\n",
      " [ 0.04823847  1.77774178 -1.00993511 -0.35875137]\n",
      " [ 0.08893745  1.96821303 -0.98958561  0.00753949]\n",
      " [ 0.29243237  2.31191595 -0.98958561  0.2313839 ]\n",
      " [-0.37910086  2.65704333 -0.96923612  0.02788898]\n",
      " [-0.60294527  0.63511782 -0.98958561 -0.62329476]\n",
      " [-0.64364425  0.77268038 -0.96923612 -0.58259578]\n",
      " [-0.56224629 -0.25863187 -0.98958561 -0.90818765]\n",
      " [-0.13490696  1.51523334 -1.00993511 -0.15525645]\n",
      " [ 0.45522831 -0.47128406 -0.96923612  0.2313839 ]\n",
      " [-0.37910086  1.10254564 -0.96923612 -0.56224629]\n",
      " [ 0.12963644  1.3847931  -1.00993511 -0.58259578]\n",
      " [-0.11455746  0.44668152 -0.96923612  0.41452932]\n",
      " [-0.48084832  1.56122319 -0.96923612 -0.98958561]\n",
      " [-0.35875137 -0.49122656 -0.98958561 -0.90818765]\n",
      " [-0.35875137 -0.46619668 -0.96923612 -0.7657412 ]\n",
      " [-0.13490696  2.41020399 -1.00993511 -0.07385848]\n",
      " [ 0.19068491  0.71631229 -0.98958561 -0.31805238]\n",
      " [ 0.55697577 -0.13755239 -0.98958561 -0.01281001]\n",
      " [-0.39945035  1.30990697 -1.00993511 -0.09420797]\n",
      " [ 0.37383034  2.2174943  -1.00993511 -0.46049883]\n",
      " [-0.01281001  0.18763249 -0.98958561 -0.48084832]\n",
      " [ 0.12963644  1.67863976 -0.96923612 -0.05350899]\n",
      " [ 0.33313136 -0.29037707 -0.98958561  0.12963644]\n",
      " [ 0.39417983 -0.41369499 -1.00993511  0.27208288]\n",
      " [ 0.57732526  1.34328013 -0.98958561 -0.0331595 ]\n",
      " [-0.01281001  1.37726378 -1.00993511  0.2313839 ]\n",
      " [-0.58259578  1.73195543 -0.98958561 -0.48084832]]\n"
     ]
    }
   ],
   "source": [
    "x_train = (x_train - x_train.mean()) / x_train.std()\n",
    "x_val = (x_val - x_val.mean()) / x_val.std()\n",
    "x_test = (x_test - x_test.mean()) / x_test.std()\n",
    "\n",
    "print(\"Normalized Training data x : \", x_train.shape)\n",
    "print(x_train)\n",
    "print(\"Normalized Validation data x : \", x_val.shape)\n",
    "print(x_val)\n",
    "print(\"Normalized Test data x : \", x_test.shape)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights :  [[0.5488135  0.71518937 0.60276338]\n",
      " [0.54488318 0.4236548  0.64589411]\n",
      " [0.43758721 0.891773   0.96366276]\n",
      " [0.38344152 0.79172504 0.52889492]]\n",
      "Initial bias :  [[0.56804456 0.92559664 0.07103606]]\n",
      "Best alpha :  0.0001\n",
      "Best validation error :  0.8916666666666664\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "w = np.random.rand(x_train.shape[1], 3)\n",
    "b = np.random.rand(1, 3)\n",
    "print(\"Initial weights : \", w)\n",
    "print(\"Initial bias : \", b)\n",
    "\n",
    "best_alpha = None\n",
    "best_val_error = float('inf')\n",
    "epochs = 1000   \n",
    "possible_alphas = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "for alpha in possible_alphas:\n",
    "    for epoch in range(epochs):\n",
    "        z = np.dot(x_train, w) + b\n",
    "        y_pred = np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "        error = y_train[:, np.newaxis] - y_pred\n",
    "        w = w + alpha * np.dot(x_train.T, error) / len(x_train)\n",
    "        b = b + alpha * np.mean(error, axis=0, keepdims=True)\n",
    "        \n",
    "        z_val = np.dot(x_val, w) + b\n",
    "        y_pred_val = np.exp(z_val) / np.sum(np.exp(z_val), axis=1, keepdims=True)\n",
    "        val_error = np.mean(np.abs(y_val[:, np.newaxis] - y_pred_val))\n",
    "        \n",
    "        if val_error < best_val_error:\n",
    "            best_val_error = val_error\n",
    "            best_alpha = alpha\n",
    "            \n",
    "print(\"Best alpha : \", best_alpha)\n",
    "print(\"Best validation error : \", best_val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining One Vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all_logistic_regression(x_train, y_train, x_val, y_val, num_classes, alpha, epochs):\n",
    "    m, n = x_train.shape\n",
    "    w = np.zeros((num_classes, n))\n",
    "    b = np.zeros((num_classes, 1))\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        y_binary = (y_train == c).astype(int)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            z = np.dot(x_train, w[c]) + b[c]\n",
    "            y_pred = sigmoid(z)\n",
    "            error = y_binary - y_pred\n",
    "            \n",
    "            w[c] += alpha * np.dot(x_train.T, error) / m\n",
    "            b[c] += alpha * np.mean(error)\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (multi-class): 0.575\n",
      "Confusion matrix (multi-class):\n",
      "[[ 5  0 16]\n",
      " [ 0  0  1]\n",
      " [ 0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "alpha = best_alpha \n",
    "epochs = 1000\n",
    "\n",
    "w, b = one_vs_all_logistic_regression(x_train, y_train, x_val, y_val, num_classes, alpha, epochs)\n",
    "\n",
    "def predict_multi_class(x, w, b):\n",
    "    z = np.dot(x, w.T) + b.T\n",
    "    y_pred_prob = sigmoid(z)\n",
    "    return np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "y_pred_test_multi = predict_multi_class(x_test, w, b)\n",
    "\n",
    "accuracy_multi = np.mean(y_test == y_pred_test_multi)\n",
    "\n",
    "print(\"Accuracy (multi-class):\", accuracy_multi)\n",
    "\n",
    "confusion_matrix_multi = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    confusion_matrix_multi[int(y_test[i])][int(y_pred_test_multi[i])] += 1\n",
    "\n",
    "print(\"Confusion matrix (multi-class):\")\n",
    "print(confusion_matrix_multi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
